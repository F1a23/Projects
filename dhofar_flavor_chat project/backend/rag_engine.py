import os
import re
import pickle
import difflib
from typing import List, Dict, Optional, Tuple
from dotenv import load_dotenv

load_dotenv()

DEBUG_MATCH = os.getenv("DEBUG_MATCH", "0") == "1"

# ===================== LOAD DATA =====================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # backend/
PROJECT_ROOT = os.path.dirname(BASE_DIR)
RECIPES_PKL = os.path.join(PROJECT_ROOT, "data", "processed", "recipes.pkl")

if not os.path.exists(RECIPES_PKL):
    raise FileNotFoundError(f"recipes.pkl not found at:\n{RECIPES_PKL}")

with open(RECIPES_PKL, "rb") as f:
    RECIPES: List[Dict] = pickle.load(f)

STATE = {"options": None, "last_intent": "all"}  # list[Dict]

# ===================== NORMALIZE =====================
_AR_DIACRITICS = r"[\u064B-\u065F\u0670]"

def normalize_ar(text: str) -> str:
    if not text:
        return ""
    t = str(text)
    t = re.sub(_AR_DIACRITICS, "", t)
    t = t.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    t = t.replace("Ù‰", "ÙŠ").replace("Ø©", "Ù‡")
    t = re.sub(r"\s+", " ", t).strip().lower()
    return t

def canonical_term(term: str) -> str:
    t = normalize_ar(term)
    t = re.sub(r"[^0-9\u0621-\u064A ]+", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    if not t:
        return ""
    # Ø´ÙŠÙ„ "Ø§Ù„" ÙÙ‚Ø· Ù„Ùˆ Ø¬Øª ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù†Øµ Ù†ÙØ³Ù‡
    return t[2:] if t.startswith("Ø§Ù„") and len(t) > 2 else t

def is_short_term(msg: str) -> bool:
    return len((msg or "").split()) <= 2

# ===================== INTENT =====================
def detect_intent(q: str) -> str:
    t = normalize_ar(q)
    wants_ing = any(w in t for w in ["Ù…ÙƒÙˆÙ†Ø§Øª", "Ù…Ù‚Ø§Ø¯ÙŠØ±", "Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª", "ingredients"])
    wants_prep = any(w in t for w in ["Ø·Ø±ÙŠÙ‚Ø©", "ØªØ­Ø¶ÙŠØ±", "ÙƒÙŠÙ", "Ø§Ø³ÙˆÙŠ", "Ø§Ø·Ø¨Ø®", "Ø®Ø·ÙˆØ§Øª", "prep", "cook"])
    if wants_ing and wants_prep:
        return "all"
    if wants_ing:
        return "ingredients"
    if wants_prep:
        return "prep"
    return "all"

# ===================== KEYWORDS EXTRACT =====================
def extract_keywords_text(text: str) -> str:
    if not text:
        return ""
    parts = re.split(r"(?:Ø§Ù„ÙƒÙ„Ù…Ø§Øª\s+Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©|ÙƒÙ„Ù…Ø§Øª\s+Ù…ÙØªØ§Ø­ÙŠØ©)\s*:\s*", str(text), maxsplit=1)
    return parts[1].strip() if len(parts) == 2 else ""

def strip_keywords_anywhere(text: str) -> str:
    if not text:
        return ""
    return re.split(r"(?:Ø§Ù„ÙƒÙ„Ù…Ø§Øª\s+Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©|ÙƒÙ„Ù…Ø§Øª\s+Ù…ÙØªØ§Ø­ÙŠØ©)\s*:\s*", str(text), maxsplit=1)[0].strip()

def keywords_only_text(r: Dict) -> str:
    desc = r.get("description", "") or ""
    prep = r.get("prep", "") or ""
    kw = " ".join([extract_keywords_text(desc), extract_keywords_text(prep)]).strip()
    return normalize_ar(kw)

# ===================== NAME MATCH (STRONG) =====================
NAME_ALIASES = {
    "Ù‚Ù…Ø§Ø­Ù‡": ["Ø§Ù„Ù‚Ù…Ø§Ø­Ø©", "Ø§Ù„Ù‚Ù…Ø§Ø­Ù‡", "Ù‚Ù…Ø§Ø­Ø©", "Ù‚Ù…Ø§Ø­Ù‡", "Ù‚Ù…Ø­Ù‡", "Ø§Ù„Ù‚Ù…Ø­Ù‡"],
    "Ù‚Ø¨ÙˆÙ„ÙŠ": ["Ù‚Ø¨ÙˆÙ„ÙŠ", "Ø§Ù„Ù‚Ø¨ÙˆÙ„ÙŠ", "Ù‚Ø¨ÙˆÙ„Ø©", "Ø§Ù„Ù‚Ø¨ÙˆÙ„Ø©", "Ù‚Ø§Ø¨ÙˆÙ„ÙŠ"],
}

def normalize_name(text: str) -> str:
    t = normalize_ar(text)

    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚Ù…Ø§Ø­Ø©
    t = t.replace("Ø§Ù„Ù‚Ù…Ø§Ø­Ø©", "Ø§Ù„Ù‚Ù…Ø§Ø­Ù‡").replace("Ù‚Ù…Ø§Ø­Ø©", "Ù‚Ù…Ø§Ø­Ù‡").replace("Ù‚Ù…Ø­Ù‡", "Ù‚Ù…Ø§Ø­Ù‡")

    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚Ø¨ÙˆÙ„ÙŠ
    t = t.replace("Ø§Ù„Ù‚Ø¨ÙˆÙ„ÙŠ", "Ù‚Ø¨ÙˆÙ„ÙŠ").replace("Ø§Ù„Ù‚Ø¨ÙˆÙ„Ø©", "Ù‚Ø¨ÙˆÙ„Ø©")

    parts = []
    for w in t.split():
        if w.startswith("Ø§Ù„") and len(w) > 2:
            parts.append(w[2:])
        else:
            parts.append(w)
    return " ".join(parts).strip()

def all_name_queries(q: str) -> List[str]:
    qn = normalize_name(q)
    out = {qn}
    for k, arr in NAME_ALIASES.items():
        kn = normalize_name(k)
        if qn == kn or qn in [normalize_name(x) for x in arr]:
            out.update([normalize_name(x) for x in arr])
    return [x for x in out if x]

def exact_name_hit(term: str, recipes: List[Dict]) -> Optional[Dict]:
    qs = all_name_queries(term)
    if not qs:
        return None
    for r in recipes:
        nm = normalize_name(r.get("name",""))
        if nm and nm in qs:
            return r
    return None

def find_by_name(term: str, recipes: List[Dict]) -> List[Dict]:
    qs = all_name_queries(term)
    if not qs:
        return []
    hits = []
    for r in recipes:
        nm = normalize_name(r.get("name",""))
        if not nm:
            continue
        if any(q == nm or q in nm or nm in q for q in qs):
            hits.append(r)
    hits.sort(key=lambda x: len(normalize_name(x.get("name",""))), reverse=True)
    return hits

def fuzzy_name_candidates(query: str, recipes: List[Dict], n: int = 6) -> List[Dict]:
    qn = normalize_name(query)
    names = [(normalize_name(r.get("name","")), r) for r in recipes if r.get("name")]
    name_only = [a for a, _ in names]
    close = difflib.get_close_matches(qn, name_only, n=n, cutoff=0.74)
    out = []
    for c in close:
        for a, r in names:
            if a == c:
                out.append(r)
    seen = set()
    uniq = []
    for r in out:
        k = normalize_name(r.get("name",""))
        if k in seen:
            continue
        seen.add(k)
        uniq.append(r)
    return uniq

# ===================== STRICT INGREDIENT MATCH (LINE BY LINE) =====================
def ingredient_patterns(term: str) -> List[str]:
    t = canonical_term(term)
    if not t:
        return []

    if t in {"Ù„Ø­Ù…", "Ù„Ø­ÙˆÙ…"}:
        return ["Ù„Ø­Ù…", "Ù„Ø­Ù…Ù‡", "Ù„Ø­ÙˆÙ…", "Ø§Ù„Ù„Ø­Ù…", "Ø§Ù„Ù„Ø­Ù…Ù‡", "Ø§Ù„Ù„Ø­ÙˆÙ…"]

    if t in {"Ø³Ù…Ùƒ", "Ø§Ø³Ù…Ø§Ùƒ", "Ø£Ø³Ù…Ø§Ùƒ"}:
        return ["Ø³Ù…Ùƒ", "Ø§Ù„Ø³Ù…Ùƒ", "Ø§Ø³Ù…Ø§Ùƒ", "Ø£Ø³Ù…Ø§Ùƒ", "Ø³Ø±Ø¯ÙŠÙ†", "ØªÙˆÙ†Ù‡", "ØªÙˆÙ†Ø©", "Ø±ÙˆØ¨ÙŠØ§Ù†", "Ø¬Ù…Ø¨Ø±ÙŠ", "Ø±Ø¨ÙŠØ§Ù†", "Ø­Ø¨Ø§Ø±", "Ù‚Ø±Ø´"]

    return [t, "Ø§Ù„" + t]

def word_boundary_regex(words: List[str]) -> re.Pattern:
    cleaned = [canonical_term(w) for w in words if canonical_term(w)]
    if not cleaned:
        return re.compile(r"a^")
    alt = "|".join(re.escape(w) for w in cleaned)
    pat = rf"(^|[^\u0621-\u064A0-9])({alt})([^\u0621-\u064A0-9]|$)"
    return re.compile(pat)

def ingredient_hit_reason(term: str, r: Dict) -> Optional[str]:
    pats = ingredient_patterns(term)
    rx = word_boundary_regex(pats)

    ing_list = r.get("ingredients") or []
    if not isinstance(ing_list, list):
        ing_list = [str(ing_list)]

    q = canonical_term(term)

    false_positive_context = {
        "Ø¨Ù‡Ø§Ø±Ø§Øª", "ØªÙˆØ§Ø¨Ù„", "Ø¨Ø²Ø§Ø±", "Ù…Ø±Ù‚", "Ù…ÙƒØ¹Ø¨", "Ù…ÙƒØ¹Ø¨Ø§Øª", "Ø¨ÙˆØ¯Ø±Ø©", "Ù…Ø³Ø­ÙˆÙ‚",
        "Ø®Ù„Ø·Ù‡", "Ø®Ù„Ø·Ø©", "ØªØªØ¨ÙŠÙ„Ø©", "ØªØªØ¨ÙŠÙ„Ù‡"
    }

    for ing in ing_list:
        original = str(ing)
        line = normalize_ar(original)

        if not rx.search(line):
            continue

        # âœ… Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø®Ø§Øµ Ù„Ù„Ø­Ù…: ØªØ¬Ø§Ù‡Ù„ "Ø¨Ù‡Ø§Ø±Ø§Øª Ù„Ø­Ù…" / "Ù…Ø±Ù‚ Ù„Ø­Ù…" ... Ø¥Ù„Ø®
        if q in {"Ù„Ø­Ù…", "Ù„Ø­ÙˆÙ…"}:
            tokens = set(re.sub(r"[^0-9\u0621-\u064A ]+", " ", line).split())
            if any(fp in tokens for fp in false_positive_context):
                continue

        return original

    return None

def find_by_ingredient_strict(term: str, recipes: List[Dict]) -> List[Tuple[Dict, str]]:
    out = []
    for r in recipes:
        reason = ingredient_hit_reason(term, r)
        if reason:
            out.append((r, reason))

    seen = set()
    uniq = []
    for r, reason in out:
        k = normalize_name(r.get("name",""))
        if k in seen:
            continue
        seen.add(k)
        uniq.append((r, reason))

    uniq.sort(key=lambda x: normalize_name(x[0].get("name","")))
    return uniq

# ===================== KEYWORDS STRICT =====================
def keyword_match_strict(query: str, kw_text: str) -> bool:
    if not kw_text:
        return False
    qn = normalize_ar(query)
    qn = re.sub(r"[^0-9\u0621-\u064A ]+", " ", qn)
    qn = re.sub(r"\s+", " ", qn).strip()
    if not qn:
        return False

    words = [canonical_term(w) for w in qn.split() if canonical_term(w)]
    if not words:
        return False

    for w in words:
        pat = re.compile(rf"(^|\s){re.escape(w)}(\s|$)")
        if not pat.search(kw_text):
            return False
    return True

def find_by_keywords_strict(term: str, recipes: List[Dict]) -> List[Tuple[Dict, str]]:
    out = []
    for r in recipes:
        kw = keywords_only_text(r)
        if kw and keyword_match_strict(term, kw):
            out.append((r, kw))

    seen = set()
    uniq = []
    for r, kw in out:
        k = normalize_name(r.get("name",""))
        if k in seen:
            continue
        seen.add(k)
        uniq.append((r, kw))

    uniq.sort(key=lambda x: normalize_name(x[0].get("name","")))
    return uniq

# ===================== SPECIAL: BAKED GOODS (UPDATED) =====================
BAKED_TRIGGER = {"Ù…Ø®Ø¨ÙˆØ²Ø§Øª", "Ù…Ø®Ø¨ÙˆØ²", "Ø®Ø¨Ø²", "Ø¹ÙŠØ´", "Ø±Ù‚Ø§Ù‚", "Ù„Ø­ÙˆØ­", "Ø±ØºÙŠÙ"}

def is_bread_recipe(r: Dict) -> bool:
    nm_raw = r.get("name","") or ""
    nm = normalize_ar(nm_raw)
    tp = normalize_ar(r.get("type","") or "")
    kw = keywords_only_text(r)

    # âœ… Ø§Ø³ØªØ«Ù†Ø§Ø¡ ÙˆØ§Ø¶Ø­: Ù‡Ø°Ø§ Ù…Ùˆ Ø®Ø¨Ø² (ÙŠØ·Ù„Ø¹ Ø¶Ù…Ù† Ø§Ù„Ø­Ù„ÙˆÙŠØ§Øª ØºØ§Ù„Ø¨Ø§Ù‹)
    if "Ø¹ÙŠØ´ Ø¨Ø§Ù„Ù†Ø§Ø±Ø¬ÙŠÙ„" in nm:
        return False

    # Ø®Ø¨Ø² ØµØ±ÙŠØ­
    if any(w in nm for w in ["Ø®Ø¨Ø²", "Ø±Ù‚Ø§Ù‚", "Ù„Ø­ÙˆØ­", "Ø±ØºÙŠÙ"]):
        return True

    # ÙƒÙ„Ù…Ø© "Ø¹ÙŠØ´" Ù„Ø­Ø§Ù„Ù‡Ø§ Ù‚Ø¯ ØªÙƒÙˆÙ† Ø­Ù„Ùˆ/Ø£Ø±Ø²... ÙÙ†Ø´ØªØ±Ø· Ù…Ø¤Ø´Ø±Ø§Øª Ø®Ø¨Ø²/Ù…Ø®Ø¨ÙˆØ²Ø§Øª
    if "Ø¹ÙŠØ´" in nm:
        if "Ø®Ø¨Ø²" in tp or "Ù…Ø®Ø¨ÙˆØ²" in tp:
            return True
        if keyword_match_strict("Ø®Ø¨Ø²", kw) or keyword_match_strict("Ù…Ø®Ø¨ÙˆØ²Ø§Øª", kw):
            return True
        return False

    if "Ø®Ø¨Ø²" in tp or "Ù…Ø®Ø¨ÙˆØ²" in tp:
        return True

    if keyword_match_strict("Ø®Ø¨Ø²", kw) or keyword_match_strict("Ù…Ø®Ø¨ÙˆØ²Ø§Øª", kw):
        return True

    return False

def find_baked_goods(recipes: List[Dict]) -> List[Dict]:
    out = [r for r in recipes if is_bread_recipe(r)]
    out.sort(key=lambda x: normalize_name(x.get("name","")))
    return out

# ===================== SPECIAL: SWEETS =====================
SWEET_TRIGGER = {"Ø­Ù„ÙˆÙŠØ§Øª", "Ø­Ù„Ø§", "ØªØ­Ù„ÙŠÙ‡", "ØªØ­Ù„ÙŠØ©", "Ø­Ù„ÙˆÙ‰", "Ø­Ù„Ùˆ", "ÙƒÙŠÙƒ", "ÙƒØ¹Ùƒ", "ÙƒØ¹ÙƒÙ‡", "ÙƒØ¹ÙƒØ©", "Ø¨Ø³Ø¨ÙˆØ³Ù‡", "Ù„Ù‚ÙŠÙ…Ø§Øª"}

SWEET_NAME_FORCE = {"Ø§Ù„Ù‚Ø´Ø§Ø·", "Ù‚Ø´Ø§Ø·", "Ø§Ù„Ù„Ø¨Ù†ÙŠÙ‡", "Ù„Ø¨Ù†ÙŠÙ‡", "Ø§Ù„Ù„Ø¨Ù†ÙŠØ©", "Ù„Ø¨Ù†ÙŠØ©", "Ø§Ù„Ø¨Ù†ÙŠÙ‡", "Ø¨Ù†ÙŠÙ‡", "Ø§Ù„Ø¨Ù†ÙŠØ©", "Ø¨Ù†ÙŠØ©"}

def is_sweet_recipe(r: Dict) -> bool:
    nm_raw = r.get("name","") or ""
    nm = normalize_ar(nm_raw)
    tp = normalize_ar(r.get("type","") or "")
    kw = keywords_only_text(r)

    if normalize_name(nm_raw) in {normalize_name(x) for x in SWEET_NAME_FORCE}:
        return True

    if "ØªØ­Ù„ÙŠÙ‡" in tp or "ØªØ­Ù„ÙŠØ©" in tp:
        return True

    if any(w in nm for w in ["ÙƒÙŠÙƒ", "ÙƒØ¹Ùƒ", "ÙƒØ¹ÙƒÙ‡", "ÙƒØ¹ÙƒØ©", "Ø¨Ø³Ø¨ÙˆØ³Ù‡", "Ù„Ù‚ÙŠÙ…Ø§Øª", "Ø­Ù„ÙˆÙŠØ§Øª", "Ø­Ù„Ø§", "Ø­Ù„ÙˆÙ‰"]):
        return True

    for w in ["Ø­Ù„ÙˆÙŠØ§Øª", "Ø­Ù„Ø§", "ØªØ­Ù„ÙŠÙ‡", "ØªØ­Ù„ÙŠØ©", "Ø­Ù„ÙˆÙ‰", "ÙƒÙŠÙƒ", "ÙƒØ¹Ùƒ", "Ø¨Ø³Ø¨ÙˆØ³Ù‡", "Ù„Ù‚ÙŠÙ…Ø§Øª", "Ù‚Ø´Ø§Ø·", "Ù„Ø¨Ù†ÙŠÙ‡", "Ù„Ø¨Ù†ÙŠØ©", "Ø¨Ù†ÙŠÙ‡", "Ø¨Ù†ÙŠØ©"]:
        if keyword_match_strict(w, kw):
            return True

    return False

def find_sweets(recipes: List[Dict]) -> List[Dict]:
    out = [r for r in recipes if is_sweet_recipe(r)]
    out.sort(key=lambda x: normalize_name(x.get("name","")))
    return out

# ===================== SPECIAL: LABNEEH KAZIB ONLY (NEW) =====================
LABNEEH_TRIGGER = {"Ù„Ø¨Ù†ÙŠÙ‡", "Ù„Ø¨Ù†ÙŠØ©", "Ø§Ù„Ù„Ø¨Ù†ÙŠÙ‡", "Ø§Ù„Ù„Ø¨Ù†ÙŠØ©", "Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ÙƒØ²ÙŠØ¨", "Ø§Ù„ÙƒØ²ÙŠØ¨", "ÙƒØ²ÙŠØ¨"}

def is_labneeh_kazib(r: Dict) -> bool:
    nm = normalize_name(r.get("name","") or "")
    return ("Ù„Ø¨Ù†ÙŠÙ‡" in nm or "Ù„Ø¨Ù†ÙŠØ©" in nm) and ("ÙƒØ²ÙŠØ¨" in nm or "Ø§Ù„ÙƒØ²ÙŠØ¨" in nm)

# ===================== DISPLAY =====================
def format_recipe(r: Dict, intent: str = "all") -> str:
    r = dict(r)
    r["description"] = strip_keywords_anywhere(r.get("description", ""))
    r["prep"] = strip_keywords_anywhere(r.get("prep", ""))

    out = f"ğŸ² {r.get('name','')}\n"
    if r.get("type"): out += f"Ù†ÙˆØ¹ Ø§Ù„Ø£ÙƒÙ„Ø©: {r['type']}\n"
    if r.get("region"): out += f"Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {r['region']}\n"
    if r.get("cook_method"): out += f"Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø·Ù‡ÙŠ: {r['cook_method']}\n"

    if intent in ("all", "description"):
        if r.get("description"):
            out += "\nğŸ“ Ø§Ù„ÙˆØµÙ:\n" + r["description"].strip()
        elif intent == "description":
            out += "\nğŸ“ Ø§Ù„ÙˆØµÙ:\nØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…ØµØ§Ø¯Ø±ÙŠ"

    if intent in ("all", "ingredients"):
        if r.get("ingredients"):
            out += "\n\nğŸ§‚ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª:\n" + "\n".join([f"- {x}" for x in r["ingredients"]])
        elif intent == "ingredients":
            out += "\n\nğŸ§‚ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª:\nØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…ØµØ§Ø¯Ø±ÙŠ"

    if intent in ("all", "prep"):
        if r.get("prep"):
            out += "\n\nğŸ‘©â€ğŸ³ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ø¶ÙŠØ±:\n" + r["prep"].strip()
        elif intent == "prep":
            out += "\n\nğŸ‘©â€ğŸ³ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ø¶ÙŠØ±:\nØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…ØµØ§Ø¯Ø±ÙŠ"

    return out.strip()

def list_names(prefix: str, items: List[Dict], max_items: int = 80) -> str:
    out = prefix.strip() + f"\n\nğŸ”¢ Ø§Ù„Ø¹Ø¯Ø¯: {len(items)}\n\n"
    for i, r in enumerate(items[:max_items], 1):
        out += f"{i}) {r.get('name','')}\n"
    if len(items) > max_items:
        out += f"\nâ€¦ (Ø¹Ø±Ø¶Ù†Ø§ Ø£ÙˆÙ„ {max_items} ÙÙ‚Ø·)\n"
    out += "\nâœï¸ Ø§ÙƒØªØ¨ÙŠ Ø±Ù‚Ù… Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±."
    return out

# ===================== LONG QUESTION -> EXTRACT DISH =====================
def extract_candidate_dish(q: str) -> str:
    t = normalize_ar(q)
    t = re.sub(
        r"\b(ÙƒÙŠÙ|Ø·Ø±ÙŠÙ‚Ø©|ØªØ­Ø¶ÙŠØ±|Ø§Ø³ÙˆÙŠ|Ø§Ø³ÙˆÙŠÙ‡Ø§|Ø§Ø·Ø¨Ø®|Ø§Ø¹Ù…Ù„|Ø¹Ù…Ù„|Ù…ÙƒÙˆÙ†Ø§Øª|Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª|Ù…Ù‚Ø§Ø¯ÙŠØ±|ÙˆØµÙÙ‡|Ø§Ù„ÙˆØµÙÙ‡|ÙˆØ´|Ø§ÙŠØ´|Ø§Ø±ÙŠØ¯|Ø§Ø¨ÙŠ)\b",
        " ",
        t
    )
    t = re.sub(r"[^0-9\u0621-\u064A ]+", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    if not t:
        return q
    parts = t.split()
    return " ".join(parts[-3:]).strip()

# ===================== MAIN ROUTER (ingredient -> keywords -> name) =====================
def answer_question(question: str) -> str:
    q = (question or "").strip()
    if not q:
        return "Ø§ÙƒØªØ¨ÙŠ: Ù…ÙƒÙˆÙ‘Ù† (Ù„Ø­Ù…/Ø³Ù…Ùƒ..) Ø£Ùˆ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© (ØªØ±Ø§Ø«ÙŠ/ØªÙ‚Ù„ÙŠØ¯ÙŠ..) Ø£Ùˆ (Ù…Ø®Ø¨ÙˆØ²Ø§Øª) Ø£Ùˆ (Ø­Ù„ÙˆÙŠØ§Øª) Ø£Ùˆ Ø§Ø³Ù… Ø£ÙƒÙ„Ø©."

    intent = detect_intent(q)
    qnorm = canonical_term(q)

    # (0) Ø§Ø®ØªÙŠØ§Ø± Ø±Ù‚Ù…
    if q.isdigit() and STATE.get("options"):
        idx = int(q) - 1
        opts = STATE["options"] or []
        if 0 <= idx < len(opts):
            picked = opts[idx]
            STATE["options"] = None
            chosen_intent = STATE.get("last_intent") or "all"
            return format_recipe(picked, chosen_intent)
        return "Ø§Ø®ØªØ§Ø±ÙŠ Ø±Ù‚Ù… ØµØ­ÙŠØ­ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©."

    # (A) Ø³Ø¤Ø§Ù„ Ø·ÙˆÙŠÙ„ -> Ø§Ø³Ù…
    if not is_short_term(q):
        cand = extract_candidate_dish(q)
        ex = exact_name_hit(cand, RECIPES) or exact_name_hit(q, RECIPES)
        if ex:
            STATE["options"] = None
            return format_recipe(ex, intent)

        hits = find_by_name(cand, RECIPES) or find_by_name(q, RECIPES)
        if not hits:
            hits = fuzzy_name_candidates(cand, RECIPES) or fuzzy_name_candidates(q, RECIPES)

        if hits:
            if len(hits) == 1:
                STATE["options"] = None
                return format_recipe(hits[0], intent)
            STATE["options"] = hits
            STATE["last_intent"] = intent
            return list_names("âœ… Ù„Ù‚ÙŠØª Ø£ÙƒØ«Ø± Ù…Ù† Ø£ÙƒÙ„Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù…Ù† Ø³Ø¤Ø§Ù„ÙƒØŒ Ø§Ø®ØªØ§Ø±ÙŠ Ø±Ù‚Ù…:", hits, 80)

    # (B) Ù…Ø®Ø¨ÙˆØ²Ø§Øª
    if qnorm in BAKED_TRIGGER:
        baked = find_baked_goods(RECIPES)
        if baked:
            STATE["options"] = baked
            STATE["last_intent"] = "all"
            return list_names("âœ… ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø®Ø¨ÙˆØ²Ø§Øª/Ø§Ù„Ø®Ø¨Ø² ÙÙ‚Ø·ØŒ Ø§Ø®ØªØ§Ø±ÙŠ Ø±Ù‚Ù…:", baked, 80)
        return "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…ØµØ§Ø¯Ø±ÙŠ"

    # âœ… (B.5) Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ÙƒØ²ÙŠØ¨ ÙÙ‚Ø· (Ù‚Ø¨Ù„ Ø§Ù„Ø­Ù„ÙˆÙŠØ§Øª)
    if normalize_ar(q) in {normalize_ar(x) for x in LABNEEH_TRIGGER}:
        only_labneeh = [r for r in RECIPES if is_labneeh_kazib(r)]
        if only_labneeh:
            STATE["options"] = only_labneeh
            STATE["last_intent"] = "all"
            return list_names("âœ… ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ÙƒØ²ÙŠØ¨ ÙÙ‚Ø·ØŒ Ø§Ø®ØªØ§Ø±ÙŠ Ø±Ù‚Ù…:", only_labneeh, 80)
        return "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…ØµØ§Ø¯Ø±ÙŠ"

    # (C) Ø­Ù„ÙˆÙŠØ§Øª
    if qnorm in SWEET_TRIGGER:
        sweets = find_sweets(RECIPES)
        if sweets:
            STATE["options"] = sweets
            STATE["last_intent"] = "all"
            return list_names("âœ… ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ø­Ù„ÙˆÙŠØ§Øª/Ø§Ù„Ø£Ø·Ø¨Ø§Ù‚ Ø§Ù„Ø­Ù„ÙˆØ© ÙÙ‚Ø·ØŒ Ø§Ø®ØªØ§Ø±ÙŠ Ø±Ù‚Ù…:", sweets, 80)
        return "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…ØµØ§Ø¯Ø±ÙŠ"

    # (1) INGREDIENTS FIRST (SUPER STRICT)
    if is_short_term(q):
        ing_hits_with_reason = find_by_ingredient_strict(q, RECIPES)
        if ing_hits_with_reason:
            ing_hits = [r for r, _ in ing_hits_with_reason]
            STATE["options"] = ing_hits
            STATE["last_intent"] = "all"

            if DEBUG_MATCH:
                debug_lines = []
                for r, reason in ing_hits_with_reason[:10]:
                    debug_lines.append(f"- {r.get('name','')}  <= matched ingredient: {reason}")
                dbg = "\n".join(debug_lines)
                return list_names(f"âœ… (DEBUG) Ø£ÙƒÙ„Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ({q}) Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª ÙÙ‚Ø·:", ing_hits, 80) + "\n\nğŸ” Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ø£ÙˆÙ„ 10):\n" + dbg

            return list_names(f"âœ… ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙƒÙ„Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ({q}) Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª/Ø§Ù„Ù…Ù‚Ø§Ø¯ÙŠØ± ÙÙ‚Ø·ØŒ Ø§Ø®ØªØ§Ø±ÙŠ Ø±Ù‚Ù…:", ing_hits, 80)

    # (2) KEYWORDS SECOND
    if is_short_term(q):
        kw_hits_with_reason = find_by_keywords_strict(q, RECIPES)
        if kw_hits_with_reason:
            kw_hits = [r for r, _ in kw_hits_with_reason]
            STATE["options"] = kw_hits
            STATE["last_intent"] = "all"

            if DEBUG_MATCH:
                debug_lines = []
                for r, kw in kw_hits_with_reason[:10]:
                    debug_lines.append(f"- {r.get('name','')}  <= keywords: {kw}")
                dbg = "\n".join(debug_lines)
                return list_names(f"âœ… (DEBUG) Ø£ÙƒÙ„Ø§Øª Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ({q}):", kw_hits, 80) + "\n\nğŸ” Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Ø£ÙˆÙ„ 10):\n" + dbg

            return list_names(f"âœ… ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙƒÙ„Ø§Øª Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ({q})ØŒ Ø§Ø®ØªØ§Ø±ÙŠ Ø±Ù‚Ù…:", kw_hits, 80)

    # (3) NAME LAST
    ex = exact_name_hit(q, RECIPES)
    if ex:
        STATE["options"] = None
        return format_recipe(ex, intent)

    name_hits = find_by_name(q, RECIPES)
    if not name_hits:
        name_hits = fuzzy_name_candidates(q, RECIPES)

    if name_hits:
        if len(name_hits) == 1:
            STATE["options"] = None
            return format_recipe(name_hits[0], intent)
        STATE["options"] = name_hits
        STATE["last_intent"] = intent
        return list_names("âœ… ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙƒØ«Ø± Ù…Ù† Ø£ÙƒÙ„Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø§Ø³Ù…ØŒ Ø§Ø®ØªØ§Ø±ÙŠ Ø±Ù‚Ù…:", name_hits, 80)

    return "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…ØµØ§Ø¯Ø±ÙŠ"
