{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0de7066-8ee0-41a3-9a75-72df8eed33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd              # Import Pandas for data loading and handling tables (DataFrames)\n",
    "import numpy as np               # Import NumPy for numerical operations and arrays\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV  # To split the dataset into training and testing sets\n",
    "from sklearn.pipeline import Pipeline                  # To create a machine learning pipeline (steps in one line)\n",
    "from sklearn.compose import ColumnTransformer          # To apply different preprocessing to different columns\n",
    "from sklearn.preprocessing import StandardScaler       # To scale numerical features (mean=0, std=1)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # To convert text into numerical features using TF-IDF\n",
    "from sklearn.linear_model import LogisticRegression    # Logistic Regression model for classification\n",
    "from sklearn.metrics import accuracy_score, classification_report  # To evaluate the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634e2c6-fb46-409e-85d0-809f83d6a8b3",
   "metadata": {},
   "source": [
    "Data Collection and Data Cleaning (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1d07fc-ffdd-4173-830c-b3ce037da7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Restaurant reviews.csv\")  \n",
    "# Load the dataset from a CSV file into a DataFrame\n",
    "\n",
    "df = df[[\"Restaurant\", \"Review\", \"Rating\"]].copy()  \n",
    "# Keep only the important columns (Restaurant, Review, Rating)\n",
    "\n",
    "df.dropna(subset=[\"Restaurant\", \"Review\", \"Rating\"], inplace=True)  \n",
    "# Remove rows that have missing values in these columns\n",
    "\n",
    "df[\"Rating\"] = df[\"Rating\"].astype(str).str.strip()  \n",
    "# Convert Rating to string and remove any extra spaces\n",
    "\n",
    "df[\"Rating\"] = pd.to_numeric(df[\"Rating\"], errors=\"coerce\")  \n",
    "# Convert Rating to numeric values, and force invalid values to NaN\n",
    "\n",
    "df.dropna(subset=[\"Rating\"], inplace=True)  \n",
    "# Remove rows where Rating could not be converted to a number\n",
    "\n",
    "# (اختياري لكن مفيد) نتأكد أن الرِيتينغ بين 1 و 5\n",
    "df = df[(df[\"Rating\"] >= 1) & (df[\"Rating\"] <= 5)]\n",
    "\n",
    "print(\"Data Shape after cleaning:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b4852-e390-46a5-b8c7-3e27ebf1a3ae",
   "metadata": {},
   "source": [
    "Target Creation (Label Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ceef29a-6858-4dbb-ad6e-8929cc1db77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "1    6268\n",
      "0    2494\n",
      "Name: count, dtype: int64\n",
      "Unique Sentiments: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# 2. CREATE SENTIMENT LABEL (BINARY)\n",
    "# =================================================\n",
    "# 0 = Negative (1 أو 2)\n",
    "# 1 = Positive (4 أو 5)\n",
    "# نحذف Rating = 3 لأنه محايد ويخبّص الدقة\n",
    "\n",
    "df = df[df[\"Rating\"] != 3]\n",
    "\n",
    "df[\"Sentiment\"] = np.where(df[\"Rating\"] >= 4, 1, 0)\n",
    "\n",
    "print(df[\"Sentiment\"].value_counts())\n",
    "print(\"Unique Sentiments:\", df[\"Sentiment\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eddb9be-8061-4a27-b521-a604663e9cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 7009\n",
      "Test size: 1753\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# 3. TRAIN–TEST SPLIT (TEXT ONLY FOR NOW)\n",
    "# =================================================\n",
    "\n",
    "X_text = df[\"Review\"]          # النص\n",
    "y = df[\"Sentiment\"]            # 0 / 1\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train_text.shape[0])\n",
    "print(\"Test size:\", X_test_text.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33e9bb93-acb8-4606-b359-f0ef7e6e4c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== BASELINE MODEL (Naive Bayes) =====\n",
      "Accuracy: 0.91500285225328\n",
      "\n",
      "Classification Report (Baseline):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83       499\n",
      "           1       0.91      0.98      0.94      1254\n",
      "\n",
      "    accuracy                           0.92      1753\n",
      "   macro avg       0.92      0.87      0.89      1753\n",
      "weighted avg       0.92      0.92      0.91      1753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# 4. BASELINE MODEL (TF-IDF + NAIVE BAYES)\n",
    "# =================================================\n",
    "\n",
    "baseline_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        ngram_range=(1, 2),     # كلمات + bigrams مثل \"not good\"\n",
    "        max_features=5000\n",
    "    )),\n",
    "    (\"model\", MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Train the baseline model\n",
    "baseline_pipeline.fit(X_train_text, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_base = baseline_pipeline.predict(X_test_text)\n",
    "\n",
    "# Accuracy\n",
    "acc_base = accuracy_score(y_test, y_pred_base)\n",
    "\n",
    "print(\"\\n===== BASELINE MODEL (Naive Bayes) =====\")\n",
    "print(\"Accuracy:\", acc_base)\n",
    "print(\"\\nClassification Report (Baseline):\")\n",
    "print(classification_report(y_test, y_pred_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4511699e-6824-49f4-a742-b594641db178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TF-IDF + FEATURE ENGINEERING (Naive Bayes + Scaled Numeric) =====\n",
      "Accuracy: 0.91500285225328\n",
      "\n",
      "Classification Report (FE):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83       499\n",
      "           1       0.91      0.98      0.94      1254\n",
      "\n",
      "    accuracy                           0.92      1753\n",
      "   macro avg       0.92      0.87      0.89      1753\n",
      "weighted avg       0.92      0.92      0.91      1753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler  # أضف هذا في قسم الـ imports فوق\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# 5. FEATURE ENGINEERING + TF-IDF + NAIVE BAYES\n",
    "# =================================================\n",
    "\n",
    "# نرجّع X_train و X_test كـ DataFrame عشان نضيف أعمدة جديدة\n",
    "X_train_fe = pd.DataFrame({\"Review\": X_train_text})\n",
    "X_test_fe  = pd.DataFrame({\"Review\": X_test_text})\n",
    "\n",
    "# ---- Feature Engineering ----\n",
    "for df_fe in [X_train_fe, X_test_fe]:\n",
    "    # طول الريفيو (عدد الحروف)\n",
    "    df_fe[\"review_length\"] = df_fe[\"Review\"].astype(str).apply(len)\n",
    "\n",
    "    # عدد الكلمات\n",
    "    df_fe[\"word_count\"] = df_fe[\"Review\"].astype(str).apply(\n",
    "        lambda x: len(x.split())\n",
    "    )\n",
    "\n",
    "    # عدد علامات التعجب !\n",
    "    df_fe[\"exclamation_count\"] = df_fe[\"Review\"].astype(str).apply(\n",
    "        lambda x: x.count(\"!\")\n",
    "    )\n",
    "\n",
    "    # نسبة الحروف الكبيرة (CAPS)\n",
    "    df_fe[\"capital_ratio\"] = df_fe[\"Review\"].astype(str).apply(\n",
    "        lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0\n",
    "    )\n",
    "\n",
    "num_features = [\"review_length\", \"word_count\", \"exclamation_count\", \"capital_ratio\"]\n",
    "\n",
    "# ColumnTransformer: TF-IDF للنص + تطبيع الفيتشرز الرقمية إلى [0, 1]\n",
    "fe_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            stop_words=\"english\",\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=5000\n",
    "        ), \"Review\"),\n",
    "        (\"num\", MinMaxScaler(), num_features)   # ✅ هنا بدلنا passthrough بـ MinMaxScaler\n",
    "    ]\n",
    ")\n",
    "\n",
    "fe_pipeline = Pipeline([\n",
    "    (\"features\", fe_preprocessor),\n",
    "    (\"model\", MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Train FE model\n",
    "fe_pipeline.fit(X_train_fe, y_train)\n",
    "\n",
    "# Predict with FE model\n",
    "y_pred_fe = fe_pipeline.predict(X_test_fe)\n",
    "\n",
    "# Accuracy for FE model\n",
    "acc_fe = accuracy_score(y_test, y_pred_fe)\n",
    "\n",
    "print(\"\\n===== TF-IDF + FEATURE ENGINEERING (Naive Bayes + Scaled Numeric) =====\")\n",
    "print(\"Accuracy:\", acc_fe)\n",
    "print(\"\\nClassification Report (FE):\")\n",
    "print(classification_report(y_test, y_pred_fe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a475874-1b07-4420-8b5c-d5f1b30d3a4f",
   "metadata": {},
   "source": [
    "Feature Engineering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c04f2-6b6f-44fe-9230-8e9bf1a1aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حساب عدد التقييمات الإيجابية لكل مطعم\n",
    "positive_counts = df[df[\"Sentiment\"] == 1][\"Restaurant\"].value_counts()\n",
    "\n",
    "# استخراج أفضل 5 مطاعم\n",
    "top_5_positive = positive_counts.head(5)\n",
    "\n",
    "print(\"Top 5 Restaurants by Positive Reviews:\")\n",
    "print(top_5_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248f30c-00c8-4f6c-9a79-5f5bb5ca20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# حساب عدد التقييمات الإيجابية لكل مطعم\n",
    "positive_counts = df[df[\"Sentiment\"] == 1][\"Restaurant\"].value_counts()\n",
    "\n",
    "# اختيار أفضل 5 فقط\n",
    "top_5_positive = positive_counts.head(5)\n",
    "\n",
    "# ألوان جميلة (Pastel)\n",
    "colors = [\"#66b3ff\", \"#99ff99\", \"#ffcc99\", \"#ff9999\", \"#c2c2f0\"]\n",
    "\n",
    "# تحديد القطعة الأكبر (Explode)\n",
    "explode = [0.05] + [0]*4   # أول قطعة فقط تخرج للخارج\n",
    "\n",
    "# الرسم\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.pie(\n",
    "    top_5_positive.values,\n",
    "    labels=top_5_positive.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=140,\n",
    "    colors=colors,\n",
    "    explode=explode,\n",
    "    shadow=True,\n",
    "    wedgeprops={\"edgecolor\":\"black\", \"linewidth\":1}\n",
    ")\n",
    "\n",
    "plt.title(\"Top 5 Restaurants by Positive Reviews\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd8d2a-a0b0-4142-b37d-c25d4a51642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حساب عدد التقييمات السلبية لكل مطعم\n",
    "negative_counts = df[df[\"Sentiment\"] == 0][\"Restaurant\"].value_counts()\n",
    "\n",
    "# اختيار أسوأ 5 فقط\n",
    "worst_5_negative = negative_counts.head(5)\n",
    "\n",
    "print(\" Worst 5 Restaurants by Negative Reviews:\")\n",
    "print(worst_5_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3aef2-5bb7-4ca5-82df-132dd5f28aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ألوان مناسبة للسلبيات\n",
    "colors = [\"#ff4d4d\", \"#ff9999\", \"#ff6666\", \"#ffb3b3\", \"#ff8080\"]\n",
    "\n",
    "# إبراز أسوأ مطعم (أكثرهم سلبيات)\n",
    "explode = [0.05] + [0]*4\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.pie(\n",
    "    worst_5_negative.values,\n",
    "    labels=worst_5_negative.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=140,\n",
    "    colors=colors,\n",
    "    explode=explode,\n",
    "    shadow=True,\n",
    "    wedgeprops={\"edgecolor\":\"black\", \"linewidth\":1}\n",
    ")\n",
    "\n",
    "plt.title(\"Worst 5 Restaurants by Negative Reviews\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb425f14-6d0e-4380-88a1-e2e78971f7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
