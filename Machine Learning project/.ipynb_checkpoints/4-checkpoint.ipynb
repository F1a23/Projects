{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073fbba3-62ff-4265-9b61-b62050cca6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after cleaning: (9955, 3)\n",
      "\n",
      "Sentiment value counts (before balancing):\n",
      "Sentiment\n",
      "1    6269\n",
      "0    2494\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample before/after cleaning:\n",
      "RAW : The ambience was good, food was quite good . had Saturday lunch , which was cost effective .\n",
      "Good place for a sate brunch. One can also chill with friends and or parents.\n",
      "Waiter Soumen Das was really courteous and helpful.\n",
      "CLEAN: the ambience was good food was quite good had saturday lunch which was cost effective good place for a sate brunch one can also chill with friends and or parents waiter soumen das was really courteous and helpful\n",
      "\n",
      "Before balancing:\n",
      "Positive: 6269\n",
      "Negative: 2494\n",
      "\n",
      "After balancing:\n",
      "Sentiment\n",
      "0    6269\n",
      "1    6269\n",
      "Name: count, dtype: int64\n",
      "Balanced shape: (12538, 5)\n",
      "\n",
      "Train size: 10030\n",
      "Test size: 2508\n",
      "\n",
      "===== BASELINE MODEL (TF-IDF + Naive Bayes, Cleaned Text) =====\n",
      "Accuracy: 0.9134768740031898\n",
      "\n",
      "Classification Report (Baseline):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      1254\n",
      "           1       0.90      0.93      0.91      1254\n",
      "\n",
      "    accuracy                           0.91      2508\n",
      "   macro avg       0.91      0.91      0.91      2508\n",
      "weighted avg       0.91      0.91      0.91      2508\n",
      "\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "===== GRIDSEARCH RESULTS (Logistic Regression, Cleaned Text) =====\n",
      "Best Params: {'model__C': 10, 'model__penalty': 'l2'}\n",
      "Best CV Score: 0.9445663010967099\n",
      "\n",
      "===== BEST LOGISTIC MODEL ON TEST SET (Cleaned Text) =====\n",
      "Accuracy: 0.9481658692185008\n",
      "\n",
      "Classification Report (Best Logistic):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1254\n",
      "           1       0.97      0.93      0.95      1254\n",
      "\n",
      "    accuracy                           0.95      2508\n",
      "   macro avg       0.95      0.95      0.95      2508\n",
      "weighted avg       0.95      0.95      0.95      2508\n",
      "\n",
      "\n",
      "===== FINAL MODEL COMPARISON =====\n",
      "                                               Model  Accuracy\n",
      "0          TF-IDF + Naive Bayes (Balanced + Cleaned)  0.913477\n",
      "1  TF-IDF + Logistic (GridSearch L1/L2, Balanced ...  0.948166\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ============================================================\n",
    "# 0. IMPORTS\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD & CLEAN RAW DATA (RATING)\n",
    "# ============================================================\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv(\"Restaurant reviews.csv\")\n",
    "\n",
    "# Keep only important columns\n",
    "df = df[[\"Restaurant\", \"Review\", \"Rating\"]].copy()\n",
    "\n",
    "# Drop rows with missing values in these columns\n",
    "df.dropna(subset=[\"Restaurant\", \"Review\", \"Rating\"], inplace=True)\n",
    "\n",
    "# Clean Rating column\n",
    "df[\"Rating\"] = df[\"Rating\"].astype(str).str.strip()\n",
    "\n",
    "# (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù„Ùˆ ÙÙŠ ÙƒÙ„Ù…Ø© \"Like\" Ù†Ø­ÙˆÙ„Ù‡Ø§ Ø¥Ù„Ù‰ 4 (ØªÙ‚ÙŠÙŠÙ… Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)\n",
    "df[\"Rating\"] = df[\"Rating\"].str.replace(\"Like\", \"4\", case=False, regex=False)\n",
    "\n",
    "# Convert Rating to numeric\n",
    "df[\"Rating\"] = pd.to_numeric(df[\"Rating\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where Rating is NaN\n",
    "df.dropna(subset=[\"Rating\"], inplace=True)\n",
    "\n",
    "# Keep only ratings between 1 and 5\n",
    "df = df[(df[\"Rating\"] >= 1) & (df[\"Rating\"] <= 5)]\n",
    "\n",
    "print(\"Data shape after cleaning:\", df.shape)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. CREATE BINARY SENTIMENT LABEL\n",
    "#    0 = Negative (1, 2)\n",
    "#    1 = Positive (4, 5)\n",
    "#    Remove neutral (3)\n",
    "# ============================================================\n",
    "df = df[df[\"Rating\"] != 3]\n",
    "\n",
    "df[\"Sentiment\"] = np.where(df[\"Rating\"] >= 4, 1, 0)\n",
    "\n",
    "print(\"\\nSentiment value counts (before balancing):\")\n",
    "print(df[\"Sentiment\"].value_counts())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. TEXT CLEANING FUNCTION (IMPROVEMENT STEP #1)\n",
    "# ============================================================\n",
    "\n",
    "def clean_text_smart(text):\n",
    "    text = str(text)\n",
    "\n",
    "    # lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
    "\n",
    "    # remove HTML\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "\n",
    "    # expand n't â†’ not\n",
    "    text = re.sub(r\"n't\\b\", \" not\", text)\n",
    "\n",
    "    # remove numbers\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "\n",
    "    # KEEP ! and ? Ù„Ø£Ù†Ù‡Ù… Ù…Ù‡Ù…ÙŠÙ† Ù„Ù„Ù…Ø´Ø§Ø¹Ø±\n",
    "    punctuation_to_remove = string.punctuation.replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "    text = text.translate(str.maketrans(\"\", \"\", punctuation_to_remove))\n",
    "\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Review\n",
    "df[\"Clean_Review\"] = df[\"Review\"].astype(str).apply(clean_text)\n",
    "\n",
    "print(\"\\nSample before/after cleaning:\")\n",
    "print(\"RAW :\", df[\"Review\"].iloc[0])\n",
    "print(\"CLEAN:\", df[\"Clean_Review\"].iloc[0])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. BALANCE THE DATA (POSITIVE = NEGATIVE)\n",
    "#    Over-sampling negative class\n",
    "# ============================================================\n",
    "df_pos = df[df[\"Sentiment\"] == 1]   # Positive reviews\n",
    "df_neg = df[df[\"Sentiment\"] == 0]   # Negative reviews\n",
    "\n",
    "print(\"\\nBefore balancing:\")\n",
    "print(\"Positive:\", len(df_pos))\n",
    "print(\"Negative:\", len(df_neg))\n",
    "\n",
    "# Over-sample the minority (negative) to match positive count\n",
    "df_neg_oversampled = df_neg.sample(len(df_pos), replace=True, random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "df_balanced = pd.concat([df_pos, df_neg_oversampled], axis=0).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"\\nAfter balancing:\")\n",
    "print(df_balanced[\"Sentiment\"].value_counts())\n",
    "print(\"Balanced shape:\", df_balanced.shape)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. TRAINâ€“TEST SPLIT (ON BALANCED DATA, USING CLEAN TEXT)\n",
    "# ============================================================\n",
    "X_text = df_balanced[\"Clean_Review\"]   # ğŸ‘ˆ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù†Ø¸Ù‘ÙÙ\n",
    "y = df_balanced[\"Sentiment\"]\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nTrain size:\", len(X_train_text))\n",
    "print(\"Test size:\", len(X_test_text))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. BASELINE MODEL: TF-IDF + NAIVE BAYES\n",
    "# ============================================================\n",
    "baseline_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        ngram_range=(1, 2),   # unigrams + bigrams\n",
    "        max_features=5000\n",
    "    )),\n",
    "    (\"model\", MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "baseline_pipeline.fit(X_train_text, y_train)\n",
    "\n",
    "y_pred_base = baseline_pipeline.predict(X_test_text)\n",
    "acc_base = accuracy_score(y_test, y_pred_base)\n",
    "\n",
    "print(\"\\n===== BASELINE MODEL (TF-IDF + Naive Bayes, Cleaned Text) =====\")\n",
    "print(\"Accuracy:\", acc_base)\n",
    "print(\"\\nClassification Report (Baseline):\")\n",
    "print(classification_report(y_test, y_pred_base))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. IMPROVED MODEL: TF-IDF + LOGISTIC REGRESSION + GRIDSEARCH\n",
    "#    L1 & L2 regularization\n",
    "# ============================================================\n",
    "logreg_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=5000\n",
    "    )),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        solver=\"liblinear\"   # supports L1 and L2\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"model__penalty\": [\"l1\", \"l2\"],       # L1 vs L2\n",
    "    \"model__C\": [0.01, 0.1, 1, 10]        # Regularization strength\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=logreg_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_text, y_train)\n",
    "\n",
    "print(\"\\n===== GRIDSEARCH RESULTS (Logistic Regression, Cleaned Text) =====\")\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best CV Score:\", grid.best_score_)\n",
    "\n",
    "best_logreg_model = grid.best_estimator_\n",
    "\n",
    "y_pred_grid = best_logreg_model.predict(X_test_text)\n",
    "acc_grid = accuracy_score(y_test, y_pred_grid)\n",
    "\n",
    "print(\"\\n===== BEST LOGISTIC MODEL ON TEST SET (Cleaned Text) =====\")\n",
    "print(\"Accuracy:\", acc_grid)\n",
    "print(\"\\nClassification Report (Best Logistic):\")\n",
    "print(classification_report(y_test, y_pred_grid))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. FINAL MODEL COMPARISON TABLE\n",
    "# ============================================================\n",
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"TF-IDF + Naive Bayes (Balanced + Cleaned)\",\n",
    "        \"TF-IDF + Logistic (GridSearch L1/L2, Balanced + Cleaned)\"\n",
    "    ],\n",
    "    \"Accuracy\": [acc_base, acc_grid]\n",
    "})\n",
    "\n",
    "print(\"\\n===== FINAL MODEL COMPARISON =====\")\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a603c64-7fb1-4ffa-b660-dd207caeac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST EXAMPLES ---\n",
      "Prediction: ğŸ‘ Positive\n",
      "Prediction: ğŸ‘ Negative\n",
      "Prediction: ğŸ‘ Positive\n",
      "Prediction: ğŸ‘ Negative\n",
      "Prediction: ğŸ‘ Positive\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TEST THE FINAL MODEL WITH NEW REVIEWS\n",
    "# ============================================================\n",
    "\n",
    "def test_review(text):\n",
    "    # Ø§Ø³ØªØ®Ø¯Ù… Ù†ÙØ³ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
    "    cleaned = clean_text_smart(text)\n",
    "\n",
    "    # ØªÙˆÙ‚Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©\n",
    "    prediction = best_logreg_model.predict([cleaned])[0]\n",
    "\n",
    "    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©\n",
    "    if prediction == 1:\n",
    "        print(\"Prediction: ğŸ‘ Positive\")\n",
    "    else:\n",
    "        print(\"Prediction: ğŸ‘ Negative\")\n",
    "\n",
    "\n",
    "# Ø¬Ø±Ù‘Ø¨ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ù…Ø«Ù„Ø©\n",
    "print(\"\\n--- TEST EXAMPLES ---\")\n",
    "\n",
    "test_review(\"The food was excellent and the staff were friendly!\")\n",
    "test_review(\"Terrible experience, the service was very slow.\")\n",
    "test_review(\"It was okay, nothing special really.\")\n",
    "test_review(\"Worst restaurant ever, I will never come again!\")\n",
    "test_review(\"Loved it! Amazing taste and great value for money.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5a6e0-b5d3-405b-a227-c3332a8dbf7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
